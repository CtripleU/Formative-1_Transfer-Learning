{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the data directories\n",
    "\n",
    "# Get the project root directory\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
    "\n",
    "# Append the src directory to the Python path\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'src'))\n",
    "\n",
    "# Declare data directories\n",
    "train_data_dir = os.path.join(ROOT_DIR, 'raw_data/training_set')\n",
    "test_data_dir = os.path.join(ROOT_DIR, 'raw_data/test_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 311 images belonging to 2 classes.\n",
      "Found 174 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image dimensions\n",
    "img_width, img_height = 224, 224 \n",
    "\n",
    "# Data augmentation for training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Rescaling for test set (no augmentation)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generate batches of image data with data augmentation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Generate batches of image data for testing\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuned_model(base_model):\n",
    "    \"\"\"\n",
    "    Creates a fine-tuned model from a pre-trained base model.\n",
    "    \"\"\"\n",
    "    # Freeze all convolutional layers in the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False \n",
    "\n",
    "    # Flatten the output of the convolutional base\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Add fully connected layers for classification\n",
    "    x = Dense(128, activation='relu')(x)  \n",
    "    predictions = Dense(1, activation='sigmoid')(x) # Binary classification\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(lr=0.0001), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "# Create instances of pre-trained models\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fine-tuned models\n",
    "vgg_model_ft = create_fine_tuned_model(vgg_model)\n",
    "resnet_model_ft = create_fine_tuned_model(resnet_model)\n",
    "inception_model_ft = create_fine_tuned_model(inception_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the models\n",
    "history_vgg = vgg_model_ft.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Adjust as needed \n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "history_resnet = resnet_model_ft.fit(\n",
    "    train_generator,\n",
    "    epochs=10, \n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "history_inception = inception_model_ft.fit(\n",
    "    train_generator,\n",
    "    epochs=10, \n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "vgg_preds = vgg_model_ft.predict(test_generator)\n",
    "resnet_preds = resnet_model_ft.predict(test_generator)\n",
    "inception_preds = inception_model_ft.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities to class labels\n",
    "vgg_preds_classes = (vgg_preds > 0.5).astype(int)\n",
    "resnet_preds_classes = (resnet_preds > 0.5).astype(int)\n",
    "inception_preds_classes = (inception_preds > 0.5).astype(int)\n",
    "\n",
    "# Get true labels from the generator\n",
    "true_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "for model_name, predictions in [('VGG16', vgg_preds_classes), \n",
    "                                 ('ResNet50', resnet_preds_classes), \n",
    "                                 ('InceptionV3', inception_preds_classes)]:\n",
    "\n",
    "    results[model_name] = {\n",
    "        'Accuracy': accuracy_score(true_labels, predictions),\n",
    "        'Loss': history_vgg.history['val_loss'][-1] if model_name == 'VGG16' else \\\n",
    "                history_resnet.history['val_loss'][-1] if model_name == 'ResNet50' else \\\n",
    "                history_inception.history['val_loss'][-1],\n",
    "        'Precision': precision_score(true_labels, predictions),\n",
    "        'Recall': recall_score(true_labels, predictions),\n",
    "        'F1 Score': f1_score(true_labels, predictions),\n",
    "        'AUC': roc_auc_score(true_labels, predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results table\n",
    "print(\"Model Performance:\")\n",
    "print(\"{:<15} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format('Model', 'Accuracy', 'Loss', 'Precision', 'Recall', 'F1 Score', 'AUC'))\n",
    "for model_name, metrics in results.items():\n",
    "    print(\"{:<15} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(model_name, metrics['Accuracy'], metrics['Loss'], metrics['Precision'], metrics['Recall'], metrics['F1 Score'], metrics['AUC']))\n",
    "\n",
    "# Plot the confusion matrices\n",
    "for model_name, predictions in [('VGG16', vgg_preds_classes), \n",
    "                                 ('ResNet50', resnet_preds_classes), \n",
    "                                 ('InceptionV3', inception_preds_classes)]:\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
